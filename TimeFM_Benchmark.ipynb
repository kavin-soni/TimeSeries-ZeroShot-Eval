{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Time Series Foundation Model Latency Benchmark
",
        "
",
        "This notebook benchmarks the inference latency of the **TimesFM** foundation model on GPU versus a traditional **XGBoost** supervised baseline on CPU. 
",
        "
",
        "### Operational Regime Context:
",
        "- **Foundation Model**: High-capacity, zero-shot, transformer-based.
",
        "- **XGBoost**: Lightweight, supervised specialist."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 1. Install Dependencies
",
        "!pip install git+https://github.com/google-research/timesfm.git
",
        "!pip install xgboost scikit-learn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 2. TimesFM GPU Benchmark
",
        "import time
",
        "import numpy as np
",
        "import torch
",
        "import timesfm
",
        "
",
        "def run_gpu_benchmark():
",
        "    CONTEXT_LEN = 512
",
        "    HORIZON_LEN = 96
",
        "    BATCH_SIZE = 1
",
        "    N_ITER = 50
",
        "    REPO_ID = "google/timesfm-1.0-200m"
",
        "
",
        "    print(f"--- TimesFM GPU Latency Benchmark ---")
",
        "    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
",
        "    print(f"Device identified: {device}")
",
        "
",
        "    # Initialize Model
",
        "    tfm = timesfm.TimesFm(
",
        "        context_len=CONTEXT_LEN,
",
        "        horizon_len=HORIZON_LEN,
",
        "        input_patch_len=32,
",
        "        output_patch_len=128,
",
        "        num_layers=20,
",
        "        model_dims=1280,
",
        "        backend="gpu" if torch.cuda.is_available() else "cpu"
",
        "    )
",
        "    tfm.load_from_checkpoint(repo_id=REPO_ID)
",
        "    
",
        "    # Prepare Dummy Data
",
        "    dummy_input = [np.random.rand(CONTEXT_LEN).astype(np.float32) for _ in range(BATCH_SIZE)]
",
        "    dummy_freq = [0] * BATCH_SIZE
",
        "
",
        "    # Warmup
",
        "    print("Warming up model...")
",
        "    for _ in range(5):
",
        "        tfm.forecast(dummy_input, freq=dummy_freq)
",
        "    if torch.cuda.is_available():
",
        "        torch.cuda.synchronize()
",
        "
",
        "    # Benchmark Loop
",
        "    print(f"Starting {N_ITER} inference runs...")
",
        "    latencies = []
",
        "    for _ in range(N_ITER):
",
        "        if torch.cuda.is_available():
",
        "            torch.cuda.synchronize()
",
        "        
",
        "        start = time.perf_counter()
",
        "        tfm.forecast(dummy_input, freq=dummy_freq)
",
        "        
",
        "        if torch.cuda.is_available():
",
        "            torch.cuda.synchronize()
",
        "            
",
        "        end = time.perf_counter()
",
        "        latencies.append((end - start) * 1000)
",
        "
",
        "    print(f"
=== TimesFM RESULTS ===")
",
        "    print(f"P50 Latency: {np.percentile(latencies, 50):.2f} ms")
",
        "    print(f"P95 Latency: {np.percentile(latencies, 95):.2f} ms")
",
        "    print(f"Throughput:  {1000/np.percentile(latencies, 50):.2f} inf/sec")
",
        "
",
        "run_gpu_benchmark()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 3. XGBoost CPU Benchmark
",
        "import xgboost as xgb
",
        "
",
        "def benchmark_xgboost():
",
        "    print(f"--- XGBoost CPU Latency Benchmark ---")
",
        "    # Setup mock trained model
",
        "    X = np.random.rand(1000, 15).astype(np.float32)
",
        "    y = np.random.rand(1000)
",
        "    bst = xgb.train({'objective': 'reg:squarederror', 'nthread': 1}, xgb.DMatrix(X, label=y))
",
        "    
",
        "    test_point = xgb.DMatrix(X[:1, :])
",
        "    
",
        "    latencies = []
",
        "    for _ in range(100):
",
        "        start = time.perf_counter()
",
        "        bst.predict(test_point)
",
        "        end = time.perf_counter()
",
        "        latencies.append((end - start) * 1000)
",
        "    
",
        "    print(f"
=== XGBoost RESULTS ===")
",
        "    print(f"P50 Latency: {np.percentile(latencies, 50):.2f} ms")
",
        "    print(f"P95 Latency: {np.percentile(latencies, 95):.2f} ms")
",
        "    print(f"Throughput:  {1000/np.percentile(latencies, 50):.2f} inf/sec")
",
        "
",
        "benchmark_xgboost()"
      ]
    }
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 4. LSTM Latency Benchmark\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Input\n",
        "\n",
        "def benchmark_lstm(lookback=168, horizon=24):\n",
        "    print(f\"--- LSTM Latency Benchmark ---\")\n",
        "    \n",
        "    # Setup standard LSTM model\n",
        "    model = Sequential([\n",
        "        Input(shape=(lookback, 1)),\n",
        "        LSTM(64, activation='tanh'),\n",
        "        Dense(horizon)\n",
        "    ])\n",
        "    \n",
        "    dummy_input = np.random.rand(1, lookback, 1).astype(np.float32)\n",
        "    \n",
        "    # Warmup\n",
        "    print(\"Warming up model...\")\n",
        "    for _ in range(10):\n",
        "        _ = model.predict(dummy_input, verbose=0)\n",
        "    \n",
        "    latencies = []\n",
        "    print(\"Starting 50 inference runs...\")\n",
        "    for _ in range(50):\n",
        "        start = time.perf_counter()\n",
        "        model.predict(dummy_input, verbose=0)\n",
        "        end = time.perf_counter()\n",
        "        latencies.append((end - start) * 1000)\n",
        "    \n",
        "    print(f\"\\n=== LSTM RESULTS ===\")\n",
        "    print(f\"P50 Latency: {np.percentile(latencies, 50):.2f} ms\")\n",
        "    print(f\"P95 Latency: {np.percentile(latencies, 95):.2f} ms\")\n",
        "    print(f\"Throughput:  {1000/np.percentile(latencies, 50):.2f} inf/sec\")\n",
        "\n",
        "benchmark_lstm()"
      ]
    }
  ],
",
  "metadata": {
    "colab": {
",
    "    "provenance": []
",
    "  },
",
    "  "kernelspec": {
",
    "    "display_name": "Python 3",
    "language": "python",
    "name": "python3"
",
    "  }
",
    "},
",
  "nbformat": 4,
",
  "nbformat_minor": 0
",
}
